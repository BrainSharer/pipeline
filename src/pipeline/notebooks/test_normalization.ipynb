{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4892eb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py    \n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cec173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(img, scale):\n",
    "    \"\"\"This is a simple opencv image normalization for 16 bit images.\n",
    "\n",
    "    :param img: the numpy array of the 16bit image\n",
    "    :return img: the normalized image\n",
    "    \"\"\"\n",
    "    #cv2.normalize(img, img, 0, max, cv2.NORM_MINMAX)\n",
    "    #norm = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    cv2.normalize(img, img, 0, scale, cv2.NORM_MINMAX)\n",
    "    return img\n",
    "\n",
    "def scaled(img, scale=20000):\n",
    "    \"\"\"First we find really high values, which are the bright spots and turn them down\n",
    "    \"\"\"\n",
    "    dtype = img.dtype    \n",
    "    epsilon = 0.99    \n",
    "    _max = np.quantile(img[img>0], epsilon)\n",
    "    scaled = (img * (scale / _max)).astype(dtype) # scale the image from original values to e.g., 30000/10000\n",
    "    del img\n",
    "    return scaled\n",
    "\n",
    "def equalized(fixed, cliplimit=2):\n",
    "    \"\"\"Takes an image that has already been scaled and uses opencv adaptive histogram\n",
    "    equalization. This cases uses 5 as the clip limit and splits the image into rows\n",
    "    and columns. A higher cliplimit will make the image brighter. A cliplimit of 1 will\n",
    "    do nothing. \n",
    "\n",
    "    :param fixed: image we are working on\n",
    "    :return: a better looking image\n",
    "    \"\"\"\n",
    "    \n",
    "    clahe = cv2.createCLAHE(clipLimit=cliplimit, tileGridSize=(8, 8))\n",
    "    fixed = clahe.apply(fixed)\n",
    "    return fixed\n",
    "\n",
    "def myhist(img, scale):\n",
    "    hist, bins = np.histogram(img.flatten(), 65536, [0, 65536])  # Collect 16 bits histogram (65536 = 2^16).\n",
    "\n",
    "    cdf = hist.cumsum()\n",
    "\n",
    "    cdf_m = np.ma.masked_equal(cdf, 0)  # Find the minimum histogram value (excluding 0)\n",
    "    cdf_m = (cdf_m - cdf_m.min())*scale/(cdf_m.max()-cdf_m.min())\n",
    "    cdf = np.ma.filled(cdf_m,0).astype('uint16')\n",
    "\n",
    "    # Now we have the look-up table...\n",
    "    return cdf[img]\n",
    "\n",
    "def myhistXXX(i):\n",
    "    _max = 2**16 - 1\n",
    "    hist, bins = np.histogram(i, _max, (0, _max))\n",
    "    # discard colors at each end of the histogram which are used by only 0.05% \n",
    "    tmp = np.where(hist > hist.sum() * 0.0005)[0]\n",
    "    i_min = tmp.min()\n",
    "    i_max = tmp.max()\n",
    "    # stretch hist\n",
    "    tmp = (i.astype(np.int32) - i_min) / (i_max - i_min) * (_max-1)\n",
    "    img = np.clip(tmp, 0, (_max-1))\n",
    "    return img.astype(np.uint16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e28745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = 'DK101'\n",
    "DIR = f'/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/{animal}/preps/tif'\n",
    "filepath = os.path.join(DIR, 'DK101_slide033_2023_02_15_axion2_S1_C1.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d1d69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For bigarr, look at 15812x43685, 16816x44463\n",
    "startrow = 43685\n",
    "endrow = 44463\n",
    "startcol = 15812\n",
    "endcol = 16816"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467145ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigarr = io.imread(filepath)\n",
    "print(f'dtype={bigarr.dtype} shape={bigarr.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acdd7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#scale = 2**16 - 1\n",
    "scale = 20000\n",
    "bigarr_scaled = scaled(bigarr, scale)\n",
    "print(f'dtype={bigarr_scaled.dtype} shape={bigarr_scaled.shape}')\n",
    "cropped = bigarr_scaled[startrow:endrow, startcol:endcol]\n",
    "print(f'dtype={cropped.dtype} shape={cropped.shape}')\n",
    "outpath = os.path.join(DIR, 'cropped_test.tif')\n",
    "io.imsave(outpath, cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd71ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath='/net/birdstore/Vessel/WBIM/Acquisition/LifeCanvas/003_20240209/00005/Scan/00060_00089/00000/tile.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea59428",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(filepath, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b506c257",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in f.keys():\n",
    "    print(key) #Names of the root level object names in HDF5 file - can be groups or datasets.\n",
    "    print(type(f[key])) # get the object type: usually group or dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d29d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the HDF5 group; key needs to be a group name from above\n",
    "group = f['CH1']\n",
    "print(type(group))\n",
    "#Checkout what keys are inside that group.\n",
    "for key in group.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229e797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = group['raw'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a3dedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'dtype={data.dtype} shape={data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08240da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [14, 10]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "plt.imshow(data[125,:,:], cmap='seismic')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aded6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 2**16 - 1\n",
    "cropped_scaled = scaled(cropped, scale)\n",
    "outpath = os.path.join(DIR, f'cropped_scaled_{scale}.tif')\n",
    "if not os.path.exists(outpath):\n",
    "    io.imsave(outpath, cropped_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098879cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cropped)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
