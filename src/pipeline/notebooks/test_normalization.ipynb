{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4892eb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from skimage import color\n",
    "from scipy.ndimage import binary_fill_holes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cec173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled(img, scale=20000):\n",
    "    dtype = img.dtype    \n",
    "    epsilon = 0.99    \n",
    "    _max = np.quantile(img[img>0], epsilon)\n",
    "    scaled = (img * (scale / _max)).astype(dtype) # scale the image from original values to e.g., 30000/10000\n",
    "    del img\n",
    "    return scaled\n",
    "\n",
    "def equalized(fixed, cliplimit=2):    \n",
    "    clahe = cv2.createCLAHE(clipLimit=cliplimit, tileGridSize=(8, 8))\n",
    "    fixed = clahe.apply(fixed)\n",
    "    return fixed\n",
    "\n",
    "def mask_with_contours(img):\n",
    "\n",
    "    new_img = color.rgb2gray(img)\n",
    "    new_img *= 255 # or any coefficient\n",
    "    new_img = new_img.astype(np.uint8)\n",
    "    new_img[(new_img > 200)] = 255\n",
    "    \n",
    "    lowerbound = 200\n",
    "    upperbound = 255\n",
    "    #all pixels value above lowerbound will  be set to upperbound \n",
    "    _, thresh = cv2.threshold(new_img.copy(), lowerbound, upperbound, cv2.THRESH_BINARY_INV)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(50,50))\n",
    "    thresh = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (8,8))\n",
    "    smoothed = cv2.morphologyEx(thresh, cv2.MORPH_ERODE, kernel)\n",
    "    inverted_thresh = cv2.bitwise_not(smoothed)\n",
    "    filled_thresh = binary_fill_holes(inverted_thresh).astype(np.uint8)\n",
    "    #return cv2.bitwise_and(img,img, mask=filled_thresh)\n",
    "    return cv2.bitwise_not(img, filled_thresh)\n",
    "    #return filled_thresh\n",
    "\n",
    "def clean(img, mask):\n",
    "    return cv2.bitwise_and(img, img, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e28745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = 'MD592'\n",
    "BASE_DIR = f'/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/{animal}/preps'\n",
    "filepath = os.path.join(BASE_DIR, 'C1/thumbnail', '100.tif')\n",
    "maskpath = os.path.join(BASE_DIR, 'masks/C1/thumbnail_masked', '100.tif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d1d69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For bigarr, look at 15812x43685, 16816x44463\n",
    "startrow = 43685\n",
    "endrow = 44463\n",
    "startcol = 15812\n",
    "endcol = 16816"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467145ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.imread(filepath)\n",
    "print(f'dtype={img.dtype} shape={img.shape}')\n",
    "mask = io.imread(maskpath)\n",
    "print(f'dtype={mask.dtype} shape={mask.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1652df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd051c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025aa60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "newimg = clean(img, mask)\n",
    "white = np.where(mask==255)\n",
    "whiterows = white[0]\n",
    "firstrow = whiterows[1]\n",
    "print(firstrow)\n",
    "print(np.max(newimg[firstrow]))\n",
    "\n",
    "\n",
    "print(f'dtype={newimg.dtype} shape={newimg.shape} first={first}')\n",
    "newimg[newimg[:,:,0] == 0] = 234\n",
    "plt.imshow(newimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acdd7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#scale = 2**16 - 1\n",
    "scale = 20000\n",
    "bigarr_scaled = scaled(bigarr, scale)\n",
    "print(f'dtype={bigarr_scaled.dtype} shape={bigarr_scaled.shape}')\n",
    "cropped = bigarr_scaled[startrow:endrow, startcol:endcol]\n",
    "print(f'dtype={cropped.dtype} shape={cropped.shape}')\n",
    "outpath = os.path.join(DIR, 'cropped_test.tif')\n",
    "io.imsave(outpath, cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aded6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 2**16 - 1\n",
    "cropped_scaled = scaled(cropped, scale)\n",
    "outpath = os.path.join(DIR, f'cropped_scaled_{scale}.tif')\n",
    "if not os.path.exists(outpath):\n",
    "    io.imsave(outpath, cropped_scaled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
