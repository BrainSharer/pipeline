{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "21f85887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import math\n",
    "import psutil\n",
    "import operator\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c9f59caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_MB(shape):\n",
    "    current_size = math.prod(shape)/1024**3\n",
    "    current_size *= 1\n",
    "    current_size *= 1024\n",
    "    return round(current_size,4)\n",
    "\n",
    "def get_size_GB(shape, dtype=None):\n",
    "    current_size = math.prod(shape)/1024**3\n",
    "    current_size *=2\n",
    "    \n",
    "    return current_size\n",
    "\n",
    "def optimize_chunk_shape_3d(image_shape, origional_chunks, output_chunks=(1,1024,1024)):\n",
    "    \n",
    "    dtype='uint16'\n",
    "    cpu_cores=os.cpu_count()\n",
    "    sim_jobs=4\n",
    "    mem=int((psutil.virtual_memory().free/1024**3)*.8)\n",
    "    chunk_limit_GB = mem / cpu_cores / 8\n",
    "    y = origional_chunks[1] if origional_chunks[1] > output_chunks[1] else output_chunks[1]\n",
    "    x = origional_chunks[2] if origional_chunks[2] > output_chunks[2] else output_chunks[2]\n",
    "\n",
    "    origional_chunks = (origional_chunks[0], y, x)\n",
    "\n",
    "    current_chunks = origional_chunks\n",
    "    current_size = get_size_GB(current_chunks, dtype)\n",
    "\n",
    "    print(current_chunks)\n",
    "    print(current_size)\n",
    "\n",
    "    if current_size > chunk_limit_GB:\n",
    "        return current_chunks\n",
    "\n",
    "    idx = 0\n",
    "    chunk_bigger_than_z = True if current_chunks[0] >= image_shape[0] else False\n",
    "    chunk_bigger_than_y = True if current_chunks[1] >= image_shape[1] else False\n",
    "    chunk_bigger_than_x = True if current_chunks[2] >= image_shape[2] else False\n",
    "\n",
    "    while current_size <= chunk_limit_GB:\n",
    "\n",
    "        # last_size = get_size_GB(current_chunks,dtype)\n",
    "        last_shape = current_chunks\n",
    "\n",
    "        # chunk_iter_idx = idx % 2\n",
    "        # if chunk_iter_idx == 0 and chunk_bigger_than_y == False:\n",
    "        #     current_chunks = (origional_chunks[0], current_chunks[1] + output_chunks[1], current_chunks[2])\n",
    "        # elif chunk_iter_idx == 1 and chunk_bigger_than_x == False:\n",
    "        #     current_chunks = (origional_chunks[0], current_chunks[1], current_chunks[2] + output_chunks[2])\n",
    "\n",
    "        # Iterate over y first then x\n",
    "        if chunk_bigger_than_y == False:\n",
    "            current_chunks = (origional_chunks[0],current_chunks[1]+output_chunks[1],current_chunks[2])\n",
    "        elif chunk_bigger_than_x == False:\n",
    "            current_chunks = (origional_chunks[0],current_chunks[1],current_chunks[2]+output_chunks[2])\n",
    "        elif chunk_bigger_than_z == False:\n",
    "            current_chunks = (origional_chunks[0] + output_chunks[0], current_chunks[1], current_chunks[2])\n",
    "\n",
    "        current_size = get_size_GB(current_chunks, dtype)\n",
    "\n",
    "        print(current_chunks)\n",
    "        print(current_size)\n",
    "        print('next step chunk limit {}'.format(current_size))\n",
    "\n",
    "        if current_size > chunk_limit_GB:\n",
    "            return last_shape\n",
    "\n",
    "        if current_chunks[0] > image_shape[0]:\n",
    "            chunk_bigger_than_z = True\n",
    "\n",
    "        if current_chunks[1] > image_shape[1]:\n",
    "            chunk_bigger_than_y = True\n",
    "\n",
    "        if current_chunks[2] > image_shape[2]:\n",
    "            chunk_bigger_than_x = True\n",
    "\n",
    "        if all([chunk_bigger_than_z, chunk_bigger_than_y, chunk_bigger_than_x]):\n",
    "            return last_shape\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "        \n",
    "def binlist(n, width=0):\n",
    "    \"\"\"Return list of bits that represent a non-negative integer.\n",
    "\n",
    "    n      -- non-negative integer\n",
    "    width  -- number of bits in returned zero-filled list (default 0)\n",
    "    \"\"\"\n",
    "    return map(int, list(bin(n)[2:].zfill(width)))\n",
    "\n",
    "def numVals(shape):\n",
    "    \"\"\"Return number of values in chunk of specified shape, given by a list of dimension lengths.\n",
    "\n",
    "    shape -- list of variable dimension sizes\"\"\"\n",
    "    print('shape', shape)\n",
    "    #if(len(shape) == 0):\n",
    "    #    return 1\n",
    "    return reduce(operator.mul, shape)\n",
    "\n",
    "def perturbShape(shape, onbits):\n",
    "    \"\"\"Return shape perturbed by adding 1 to elements corresponding to 1 bits in onbits\n",
    "\n",
    "    shape  -- list of variable dimension sizes\n",
    "    onbits -- non-negative integer less than 2**len(shape)\n",
    "    \"\"\"\n",
    "    return map(sum, zip(shape, binlist(onbits, len(shape))))        \n",
    "\n",
    "def chunk_shape_3D(varShape, valSize=4, chunkSize=4096):\n",
    "    \"\"\"\n",
    "    Return a 'good shape' for a 3D variable, assuming balanced 1D/(n-1)D access\n",
    "\n",
    "    varShape  -- length 3 list of variable dimension sizes\n",
    "    chunkSize -- maximum chunksize desired, in bytes (default 4096)\n",
    "    valSize   -- size of each data value, in bytes (default 4)\n",
    "\n",
    "    Returns integer chunk lengths of a chunk shape that provides\n",
    "    balanced access of 1D subsets and 2D subsets of a netCDF or HDF5\n",
    "    variable var with shape (T, X, Y), where the 1D subsets are of the\n",
    "    form var[:,x,y] and the 2D slices are of the form var[t,:,:],\n",
    "    typically 1D time series and 2D spatial slices.  'Good shape' for\n",
    "    chunks means that the number of chunks accessed to read either\n",
    "    kind of 1D or 2D subset is approximately equal, and the size of\n",
    "    each chunk (uncompressed) is no more than chunkSize, which is\n",
    "    often a disk block size.\n",
    "    \"\"\"\n",
    "\n",
    "    rank = 3\n",
    "    chunkVals = chunkSize / float(valSize) # ideal number of values in a chunk\n",
    "    numChunks  = varShape[0]*varShape[1]*varShape[2] / chunkVals # ideal number of chunks\n",
    "    axisChunks = numChunks ** 0.25 # ideal number of chunks along each 2D axis\n",
    "    cFloor = [] # will be first estimate of good chunk shape\n",
    "    # cFloor  = [varShape[0] // axisChunks**2, varShape[1] // axisChunks, varShape[2] // axisChunks]\n",
    "    # except that each chunk shape dimension must be at least 1\n",
    "    # chunkDim = max(1.0, varShape[0] // axisChunks**2)\n",
    "    if varShape[0] / axisChunks**2 < 1.0:\n",
    "        chunkDim = 1.0\n",
    "        axisChunks = axisChunks / math.sqrt(varShape[0]/axisChunks**2)\n",
    "    else:\n",
    "        chunkDim = varShape[0] // axisChunks**2\n",
    "    cFloor.append(chunkDim)\n",
    "    prod = 1.0  # factor to increase other dims if some must be increased to 1.0\n",
    "    for i in range(1, rank):\n",
    "        if varShape[i] / axisChunks < 1.0:\n",
    "            prod *= axisChunks / varShape[i]\n",
    "    for i in range(1, rank):\n",
    "        if varShape[i] / axisChunks < 1.0:\n",
    "            chunkDim = 1.0\n",
    "        else:\n",
    "            chunkDim = (prod*varShape[i]) // axisChunks\n",
    "        cFloor.append(chunkDim)\n",
    "\n",
    "    # cFloor is typically too small, (numVals(cFloor) < chunkSize)\n",
    "    # Adding 1 to each shape dim results in chunks that are too large,\n",
    "    # (numVals(cCeil) > chunkSize).  Want to just add 1 to some of the\n",
    "    # axes to get as close as possible to chunkSize without exceeding\n",
    "    # it.  Here we use brute force, compute numVals(cCand) for all\n",
    "    # 2**rank candidates and return the one closest to chunkSize\n",
    "    # without exceeding it.\n",
    "    bestChunkSize = 0\n",
    "    cBest = cFloor\n",
    "    for i in range(8):\n",
    "        # cCand = map(sum,zip(cFloor, binlist(i, rank)))\n",
    "        cCand = perturbShape(cFloor, i)\n",
    "        thisChunkSize = valSize * numVals(cCand)\n",
    "        if bestChunkSize < thisChunkSize <= chunkSize:\n",
    "            bestChunkSize = thisChunkSize\n",
    "            cBest = list(cCand) # make a copy of best candidate so far\n",
    "    return map(int, cBest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "84fd3716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138, 854, 568) size 0.12468534708023071GB\n",
      "(3, 9240, 10860) size 0.5607292056083679GB\n"
     ]
    }
   ],
   "source": [
    "shape = (138, 854, 568)\n",
    "print(f'{shape} size {get_size_GB(shape)}GB')\n",
    "shape = (3, 36962//4, 43442//4)\n",
    "print(f'{shape} size {get_size_GB(shape)}GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c4f87f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape <map object at 0x7ebda659fa60>\n",
      "shape <map object at 0x7ebda659f580>\n",
      "shape <map object at 0x7ebda659eb30>\n",
      "shape <map object at 0x7ebda659fa90>\n",
      "shape <map object at 0x7ebda659fa60>\n",
      "shape <map object at 0x7ebda659f580>\n",
      "shape <map object at 0x7ebda659eb30>\n",
      "shape <map object at 0x7ebda659fa90>\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#optimum_chunks = \n",
    "#utils.optimize_chunk_shape_3d_2(\n",
    "#test_image.shape,\n",
    "#test_image.chunks,\n",
    "#self.origionalChunkSize[2:],test_image.dtype,self.res0_chunk_limit_GB)\n",
    "   \n",
    "\n",
    "image_shape = (4750, 36962, 43442)\n",
    "original_chunks = (1, 1024, 1024)\n",
    "image_chunks=(250, 1536, 1024)\n",
    "#chunks = optimize_chunk_shape_3d(image_shape, image_chunks)\n",
    "chunks = chunk_shape_3D(image_shape)\n",
    "print(list(chunks))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
