{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import ast\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neuroglancer\n",
    "from tqdm import tqdm\n",
    "from skimage import io\n",
    "import imagesize\n",
    "\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "PATH = os.path.join(HOME, 'programming/pipeline_utility/src')\n",
    "sys.path.append(PATH)\n",
    "from Controllers.SqlController import SqlController\n",
    "from lib.FileLocationManager import DATA_PATH, FileLocationManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = 'MD589'\n",
    "downsample_factor = 32\n",
    "all_structures = False\n",
    "# OUTPUT_DIR_PATH = os.path.join(os.path.expanduser('~'))\n",
    "OUTPUT_DIR_PATH = os.path.join('./')\n",
    "CSV_DIR_PATH = '/net/birdstore/Active_Atlas_Data/data_root/atlas_data/foundation_brain_annotations'\n",
    "INPUT = f'/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/{animal}/preps/CH1/thumbnail'\n",
    "sqlController = SqlController(animal)\n",
    "resolution = sqlController.scan_run.resolution\n",
    "aligned_shape = np.array((sqlController.scan_run.width, sqlController.scan_run.height))\n",
    "num_section = len(os.listdir(INPUT))\n",
    "downsampled_aligned_shape = np.round(aligned_shape / downsample_factor).astype(int)\n",
    "scales = np.array([resolution * downsample_factor, resolution * downsample_factor, 20]) * 1000\n",
    "\n",
    "db_structures = sqlController.get_structures_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14464., 14464., 20000.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the annotation points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dense_coordinates(coor_list):\n",
    "    dense_coor_list = []\n",
    "    # Shortest distance, x, y\n",
    "\n",
    "    # for x, y in coor_list:\n",
    "    for i in range(len(coor_list) - 1):\n",
    "        x, y = coor_list[i]\n",
    "        x_next, y_next = coor_list[i + 1]\n",
    "\n",
    "        x_mid = (x + x_next) / 2\n",
    "        y_mid = (y + y_next) / 2\n",
    "\n",
    "        dense_coor_list.append([x, y])\n",
    "        dense_coor_list.append([x_mid, y_mid])\n",
    "\n",
    "        if i == len(coor_list) - 2:\n",
    "            dense_coor_list.append([x_next, y_next])\n",
    "            x, y = coor_list[0]\n",
    "            x_mid = (x + x_next) / 2\n",
    "            y_mid = (y + y_next) / 2\n",
    "            dense_coor_list.append([x_mid, y_mid])\n",
    "\n",
    "    return dense_coor_list\n",
    "\n",
    "def get_contours_from_annotations(stack, target_structure, hand_annotations, densify=0):\n",
    "    MD585_ng_section_min = 83\n",
    "    num_annotations = len(hand_annotations)\n",
    "    str_contours_annotation = {}\n",
    "\n",
    "    for i in range(num_annotations):\n",
    "        structure = hand_annotations['name'][i]\n",
    "        side = hand_annotations['side'][i]\n",
    "        section = hand_annotations['section'][i]\n",
    "        first_sec = 0\n",
    "        last_sec = 0\n",
    "\n",
    "        #if side == 'R' or side == 'L':\n",
    "        #    structure = structure + '_' + side\n",
    "\n",
    "        if structure == target_structure:\n",
    "            vertices = hand_annotations['vertices'][i]\n",
    "\n",
    "            for i in range(densify):\n",
    "                vertices = get_dense_coordinates(vertices)\n",
    "\n",
    "            # Skip sections before the 22nd prep2 section for MD585 as there are clear errors\n",
    "            if stack == 'MD585' and section < MD585_ng_section_min + 22:\n",
    "                # vertices = vertices - np.array(MD585_abberation_correction)\n",
    "                continue\n",
    "            str_contours_annotation[section] = {}\n",
    "            str_contours_annotation[section][structure] = {}\n",
    "            str_contours_annotation[section][structure][1] = vertices\n",
    "\n",
    "    try:\n",
    "        first_sec = np.min(list(str_contours_annotation.keys()))\n",
    "        last_sec = np.max(list(str_contours_annotation.keys()))\n",
    "    except:\n",
    "        pass\n",
    "    return str_contours_annotation, first_sec, last_sec\n",
    "\n",
    "csvfile = os.path.join(CSV_DIR_PATH, f'{animal}_annotation.csv')\n",
    "hand_annotations = pd.read_csv(csvfile)\n",
    "hand_annotations['vertices'] = hand_annotations['vertices'] \\\n",
    "    .apply(lambda x: x.replace(' ', ','))\\\n",
    "    .apply(lambda x: x.replace('\\n',','))\\\n",
    "    .apply(lambda x: x.replace(',]',']'))\\\n",
    "    .apply(lambda x: x.replace(',,', ','))\\\n",
    "    .apply(lambda x: x.replace(',,', ','))\\\n",
    "    .apply(lambda x: x.replace(',,', ',')).apply(lambda x: x.replace(',,', ','))\n",
    "hand_annotations['vertices'] = hand_annotations['vertices'].apply(lambda x: ast.literal_eval(x))\n",
    "csv_structures = hand_annotations['name'].unique()\n",
    "\n",
    "selected_structures = csv_structures if all_structures else db_structures\n",
    "section_structure_vertices = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:01<00:00, 41.73it/s]\n"
     ]
    }
   ],
   "source": [
    "for structure in tqdm(selected_structures):\n",
    "    contour_annotations, first_sec, last_sec = get_contours_from_annotations(animal, structure, hand_annotations, densify=0)\n",
    "    for section in contour_annotations:\n",
    "        section_structure_vertices[section][structure] = contour_annotations[section][structure][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce create_clean transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 447/447 [00:06<00:00, 67.36it/s] \n"
     ]
    }
   ],
   "source": [
    "section_offset = {}\n",
    "for file_name in tqdm(sorted(os.listdir(INPUT))):\n",
    "    filepath = os.path.join(INPUT, file_name)\n",
    "    width, height = imagesize.get(filepath)\n",
    "    downsampled_shape = np.array((width, height))    \n",
    "    section = int(file_name.split('.')[0])\n",
    "    section_offset[section] = (downsampled_aligned_shape - downsampled_shape) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([74., 74.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_offset[240]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce create_alignment transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_elastix_parameter_file(filepath, tf_type=None):\n",
    "    \"\"\"\n",
    "    Parse elastix parameter result file.\n",
    "    \"\"\"\n",
    "    def parameter_elastix_parameter_file_to_dict(filename):\n",
    "        d = {}\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                if line.startswith('('):\n",
    "                    tokens = line[1:-2].split(' ')\n",
    "                    key = tokens[0]\n",
    "                    if len(tokens) > 2:\n",
    "                        value = []\n",
    "                        for v in tokens[1:]:\n",
    "                            try:\n",
    "                                value.append(float(v))\n",
    "                            except ValueError:\n",
    "                                value.append(v)\n",
    "                    else:\n",
    "                        v = tokens[1]\n",
    "                        try:\n",
    "                            value = (float(v))\n",
    "                        except ValueError:\n",
    "                            value = v\n",
    "                    d[key] = value\n",
    "            return d\n",
    "\n",
    "    d = parameter_elastix_parameter_file_to_dict(filepath)\n",
    "\n",
    "    if tf_type is None:\n",
    "        # For alignment composition script\n",
    "        rot_rad, x_mm, y_mm = d['TransformParameters']\n",
    "        center = np.array(d['CenterOfRotationPoint']) / np.array(d['Spacing'])\n",
    "        # center[1] = d['Size'][1] - center[1]\n",
    "\n",
    "        xshift = x_mm / d['Spacing'][0]\n",
    "        yshift = y_mm / d['Spacing'][1]\n",
    "\n",
    "        R = np.array([[np.cos(rot_rad), -np.sin(rot_rad)],\n",
    "                      [np.sin(rot_rad), np.cos(rot_rad)]])\n",
    "        shift = center + (xshift, yshift) - np.dot(R, center)\n",
    "        T = np.vstack([np.column_stack([R, shift]), [0, 0, 1]])\n",
    "        return T\n",
    "\n",
    "    elif tf_type == 'rigid3d':\n",
    "        p = np.array(d['TransformParameters'])\n",
    "        center = np.array(d['CenterOfRotationPoint']) / np.array(d['Spacing'])\n",
    "        shift = p[3:] / np.array(d['Spacing'])\n",
    "\n",
    "        thetax, thetay, thetaz = p[:3]\n",
    "        # Important to use the negative angle.\n",
    "        cx = np.cos(-thetax)\n",
    "        cy = np.cos(-thetay)\n",
    "        cz = np.cos(-thetaz)\n",
    "        sx = np.sin(-thetax)\n",
    "        sy = np.sin(-thetay)\n",
    "        sz = np.sin(-thetaz)\n",
    "        Rx = np.array([[1, 0, 0], [0, cx, sx], [0, -sx, cx]])\n",
    "        Ry = np.array([[cy, 0, sy], [0, 1, 0], [-sy, 0, cy]])\n",
    "        Rz = np.array([[cz, sz, 0], [-sz, cz, 0], [0, 0, 1]])\n",
    "\n",
    "        R = np.dot(np.dot(Rz, Ry), Rx)\n",
    "        # R = np.dot(np.dot(Rx, Ry), Rz)\n",
    "        # The order could be Rx,Ry,Rz - not sure.\n",
    "\n",
    "        return R, shift, center\n",
    "\n",
    "    elif tf_type == 'affine3d':\n",
    "        p = np.array(d['TransformParameters'])\n",
    "        L = p[:9].reshape((3, 3))\n",
    "        shift = p[9:] / np.array(d['Spacing'])\n",
    "        center = np.array(d['CenterOfRotationPoint']) / np.array(d['Spacing'])\n",
    "        # shift = center + shift - np.dot(L, center)\n",
    "        # T = np.column_stack([L, shift])\n",
    "        return L, shift, center\n",
    "\n",
    "    elif tf_type == 'bspline3d':\n",
    "        n_params = d['NumberOfParameters']\n",
    "        p = np.array(d['TransformParameters'])\n",
    "        grid_size = d['GridSize']\n",
    "        grid_spacing = d['GridSpacing']\n",
    "        grid_origin = d['GridOrigin']\n",
    "\n",
    "        return L, shift, center\n",
    "\n",
    "def load_consecutive_section_transform(stack, moving_fn, fixed_fn):\n",
    "    \"\"\"\n",
    "    Load pairwise transform.\n",
    "\n",
    "    Returns:\n",
    "        (3,3)-array.\n",
    "    \"\"\"\n",
    "    assert stack is not None\n",
    "    fileLocationManager = FileLocationManager(stack)\n",
    "    elastix_output_dir = fileLocationManager.elastix_dir\n",
    "    param_fp = os.path.join(elastix_output_dir, moving_fn + '_to_' + fixed_fn, 'TransformParameters.0.txt')\n",
    "    #sys.stderr.write('Load elastix-computed transform: %s\\n' % param_fp)\n",
    "    if not os.path.exists(param_fp):\n",
    "        raise Exception('Transform file does not exist: %s to %s, %s' % (moving_fn, fixed_fn, param_fp))\n",
    "    transformation_to_previous_sec = parse_elastix_parameter_file(param_fp)\n",
    "\n",
    "    return transformation_to_previous_sec\n",
    "\n",
    "def parse_elastix(animal):\n",
    "    \"\"\"\n",
    "    After the elastix job is done, this goes into each subdirectory and parses the Transformation.0.txt file\n",
    "    Args:\n",
    "        animal: the animal\n",
    "    Returns: a dictionary of key=filename, value = coordinates\n",
    "    \"\"\"\n",
    "    fileLocationManager = FileLocationManager(animal)\n",
    "    DIR = fileLocationManager.prep\n",
    "    INPUT = os.path.join(DIR, 'CH1', 'thumbnail_cleaned')\n",
    "\n",
    "    image_name_list = sorted(os.listdir(INPUT))\n",
    "    anchor_idx = len(image_name_list) // 2\n",
    "    # anchor_idx = len(image_name_list) - 1\n",
    "    transformation_to_previous_sec = {}\n",
    "\n",
    "    for i in range(1, len(image_name_list)):\n",
    "        fixed_fn = os.path.splitext(image_name_list[i - 1])[0]\n",
    "        moving_fn = os.path.splitext(image_name_list[i])[0]\n",
    "        transformation_to_previous_sec[i] = load_consecutive_section_transform(animal, moving_fn, fixed_fn)\n",
    "\n",
    "    transformation_to_anchor_sec = {}\n",
    "    # Converts every transformation\n",
    "    for moving_idx in range(len(image_name_list)):\n",
    "        if moving_idx == anchor_idx:\n",
    "            transformation_to_anchor_sec[image_name_list[moving_idx]] = np.eye(3)\n",
    "        elif moving_idx < anchor_idx:\n",
    "            T_composed = np.eye(3)\n",
    "            for i in range(anchor_idx, moving_idx, -1):\n",
    "                T_composed = np.dot(np.linalg.inv(transformation_to_previous_sec[i]), T_composed)\n",
    "            transformation_to_anchor_sec[image_name_list[moving_idx]] = T_composed\n",
    "        else:\n",
    "            T_composed = np.eye(3)\n",
    "            for i in range(anchor_idx + 1, moving_idx + 1):\n",
    "                T_composed = np.dot(transformation_to_previous_sec[i], T_composed)\n",
    "            transformation_to_anchor_sec[image_name_list[moving_idx]] = T_composed\n",
    "\n",
    "    return transformation_to_anchor_sec\n",
    "\n",
    "def create_warp_transforms(transforms, downsample_factor=32):\n",
    "    def convert_2d_transform_forms(arr):\n",
    "        return np.vstack([arr, [0, 0, 1]])\n",
    "    \n",
    "    transforms_scale_factor = 32 / downsample_factor \n",
    "    tf_mat_mult_factor = np.array([[1, 1, transforms_scale_factor], [1, 1, transforms_scale_factor]])\n",
    "    transforms_to_anchor = {}\n",
    "    for img_name, tf in transforms.items():\n",
    "        transforms_to_anchor[img_name] = convert_2d_transform_forms(np.reshape(tf, (3, 3))[:2] * tf_mat_mult_factor) \n",
    "\n",
    "    return transforms_to_anchor\n",
    "\n",
    "transforms = parse_elastix(animal)\n",
    "warp_transforms = create_warp_transforms(transforms, downsample_factor)\n",
    "ordered_transforms = sorted(warp_transforms.items())\n",
    "\n",
    "section_transform = {}\n",
    "for section, transform in ordered_transforms:\n",
    "    section_num = int(section.split('.')[0])\n",
    "    transform = np.linalg.inv(transform)\n",
    "    section_transform[section_num] = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.99958591,  -0.02877503,  10.99056027],\n",
       "       [  0.02877503,   0.99958591, -17.64599495],\n",
       "       [  0.        ,   0.        ,   1.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_transform[200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment of annotation coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_create_alignment(points, transform):\n",
    "    '''\n",
    "    (x, y) = points[i]\n",
    "    T = transform\n",
    "    \n",
    "    (x', y') = (x * sx + y * ry + tx, x * rx + y * sy + ty)\n",
    "    'sx': T[0, 0], 'sy': T[1, 1], 'rx': T[1, 0], 'ry': T[0, 1], 'tx': T[0, 2], 'ty': T[1, 2]\n",
    "    '''\n",
    "    a = np.hstack((points, np.ones((points.shape[0], 1))))\n",
    "    b = transform.T[:, 0:2]\n",
    "    c = np.matmul(a, b)\n",
    "    return c\n",
    "\n",
    "aligned_section_structure_polygons = defaultdict(dict)\n",
    "for section in section_structure_vertices:\n",
    "    for structure in section_structure_vertices[section]:\n",
    "        points = np.array(section_structure_vertices[section][structure]) // downsample_factor\n",
    "        points = points + section_offset[section] # create_clean offset\n",
    "        points = transform_create_alignment(points, section_transform[section]) # create_alignment transform\n",
    "        aligned_section_structure_polygons[section][structure] = [points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[867.07488189, 356.64284308],\n",
       "        [864.07612416, 356.55651799],\n",
       "        [862.10572736, 355.49938203],\n",
       "        [860.13533056, 354.44224606],\n",
       "        [859.16451967, 353.41388512],\n",
       "        [857.19412287, 352.35674915],\n",
       "        [856.25208702, 350.32880229],\n",
       "        [855.31005116, 348.30085544],\n",
       "        [854.33924027, 347.2724945 ],\n",
       "        [853.39720441, 345.24454765],\n",
       "        [853.4835295 , 342.24578991],\n",
       "        [853.54107955, 340.24661808],\n",
       "        [853.62740463, 337.24786034],\n",
       "        [853.68495469, 335.24868851],\n",
       "        [853.77127977, 332.24993078],\n",
       "        [854.82841574, 330.27953398],\n",
       "        [854.88596579, 328.28036215],\n",
       "        [855.94310176, 326.30996535],\n",
       "        [856.02942685, 323.31120761],\n",
       "        [855.08739099, 321.28326076],\n",
       "        [855.17371607, 318.28450302],\n",
       "        [855.23126613, 316.28533119],\n",
       "        [854.28923027, 314.25738434],\n",
       "        [854.37555535, 311.2586266 ],\n",
       "        [854.43310541, 309.25945477],\n",
       "        [854.49065546, 307.26028295],\n",
       "        [855.54779143, 305.28988615],\n",
       "        [856.6049274 , 303.31948935],\n",
       "        [858.63287425, 302.37745349],\n",
       "        [860.63204608, 302.43500355],\n",
       "        [862.65999293, 301.49296769],\n",
       "        [865.65875067, 301.57929277],\n",
       "        [867.6579225 , 301.63684283],\n",
       "        [870.65668024, 301.72316791],\n",
       "        [872.65585206, 301.78071796],\n",
       "        [874.62624886, 302.83785393],\n",
       "        [876.62542069, 302.89540399],\n",
       "        [878.59581749, 303.95253995],\n",
       "        [880.56621429, 305.00967592],\n",
       "        [881.50825014, 307.03762278],\n",
       "        [882.47906103, 308.06598372],\n",
       "        [883.42109689, 310.09393057],\n",
       "        [884.36313275, 312.12187743],\n",
       "        [885.33394363, 313.15023837],\n",
       "        [885.24761855, 316.14899611],\n",
       "        [886.18965441, 318.17694296],\n",
       "        [886.13210435, 320.17611479],\n",
       "        [887.07414021, 322.20406164],\n",
       "        [886.98781513, 325.20281938],\n",
       "        [886.90149004, 328.20157712],\n",
       "        [886.84393999, 330.20074895],\n",
       "        [885.75802899, 333.17073166],\n",
       "        [884.70089302, 335.14112846],\n",
       "        [884.672118  , 336.14071437],\n",
       "        [883.61498203, 338.11111117],\n",
       "        [881.55826015, 340.05273294],\n",
       "        [880.50112418, 342.02312974],\n",
       "        [880.47234915, 343.02271565],\n",
       "        [879.41521318, 344.99311245],\n",
       "        [877.38726633, 345.93514831],\n",
       "        [876.33013036, 347.90554511],\n",
       "        [875.27299439, 349.87594191],\n",
       "        [873.24504754, 350.81797776],\n",
       "        [872.18791157, 352.78837456],\n",
       "        [871.15955063, 353.75918545],\n",
       "        [869.13160378, 354.70122131],\n",
       "        [868.10324284, 355.67203219]])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_section_structure_polygons[200]['IC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "vertices_path = os.path.join(OUTPUT_DIR_PATH, f'{animal}_aligned_section_structure_polygons_down{downsample_factor}.pickle')\n",
    "with open(vertices_path, 'wb') as file:\n",
    "    pickle.dump(aligned_section_structure_polygons, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this point, aligned_section_structure_polygons variable contains the aligned polygon vertices for each structure in each section. \n",
    "From now on, we introduce how to draw these points to numpy array or neuroglancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw in a numpy volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 447/447 [00:04<00:00, 95.74it/s] \n"
     ]
    }
   ],
   "source": [
    "def draw_numpy(section_structure_polygons, section_start, section_end):\n",
    "    volume = np.zeros((downsampled_aligned_shape[1], downsampled_aligned_shape[0], section_end - section_start), dtype=np.uint8)\n",
    "    for section in tqdm(range(section_start, section_end)):\n",
    "        if section in section_structure_polygons:\n",
    "            template = np.zeros((downsampled_aligned_shape[1], downsampled_aligned_shape[0]), dtype=np.uint8)\n",
    "            for structure in section_structure_polygons[section]:\n",
    "                polygons = section_structure_polygons[section][structure]\n",
    "                for polygon in polygons:\n",
    "                    #color = get_structure_number(structure)\n",
    "                    color = 10\n",
    "#                     cv2.polylines(template, [polygon.astype(np.int32)], True, color, 1)\n",
    "                    for point in polygon:\n",
    "                        cv2.circle(template, tuple(point.astype(np.int32)), 0, color, -1)\n",
    "\n",
    "            volume[:, :, section - section_start - 1] = template\n",
    "        \n",
    "    volume = np.swapaxes(volume, 0, 1)\n",
    "    return volume\n",
    "\n",
    "volume = draw_numpy(aligned_section_structure_polygons, 0, num_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1366, 1012, 447)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_path = os.path.join(OUTPUT_DIR_PATH, f'{animal}_annotations_down{downsample_factor}.npy')\n",
    "with open(numpy_path, 'wb') as file:\n",
    "    np.save(file, volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:39595/v/273f14cbeba5522e346ae50c3df1f173f404df65/\n"
     ]
    }
   ],
   "source": [
    "import neuroglancer\n",
    "viewer = neuroglancer.Viewer()\n",
    "print(viewer)\n",
    "\n",
    "all_volume_layer = neuroglancer.SegmentationLayer(\n",
    "    source = neuroglancer.LocalVolume(\n",
    "        data=volume, \n",
    "        dimensions=neuroglancer.CoordinateSpace(names=['x', 'y', 'z'], units='nm', scales=scales), \n",
    "        voxel_offset=[0,0,0]\n",
    "    ),\n",
    ")\n",
    "\n",
    "with viewer.txn() as s:\n",
    "    s.layers['all'] = all_volume_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MD589_CVAT_down32.pkl', 'rb') as file:\n",
    "    cvat_section_structure_polygons = pickle.load(file)\n",
    "volume = draw_numpy(cvat_section_structure_polygons, 0, num_section)\n",
    "\n",
    "all_volume_layer = neuroglancer.SegmentationLayer(\n",
    "    source = neuroglancer.LocalVolume(\n",
    "        data=volume, \n",
    "        dimensions=neuroglancer.CoordinateSpace(names=['x', 'y', 'z'], units='nm', scales=scales), \n",
    "        voxel_offset=[0,0,0]\n",
    "    ),\n",
    ")\n",
    "\n",
    "with viewer.txn() as s:\n",
    "    s.layers['cvat'] = all_volume_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
