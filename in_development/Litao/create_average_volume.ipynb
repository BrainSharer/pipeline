{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import neuroglancer\n",
    "from matplotlib import pyplot as plt\n",
    "import tinybrain\n",
    "from cloudvolume import CloudVolume\n",
    "from taskqueue import LocalTaskQueue\n",
    "import igneous.task_creation as tc\n",
    "\n",
    "viewer = neuroglancer.Viewer()\n",
    "print(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "color_filepath = os.path.join('../', 'neuroglancer/contours/json_cache', 'struct_to_color_2.json')\n",
    "with open(color_filepath, 'r') as json_file:\n",
    "    colors = json.load(json_file)\n",
    "colors = {name.upper(): index for name, index in colors.items()}\n",
    "    \n",
    "surround = False\n",
    "VOL_DIR = '/net/birdstore/Active_Atlas_Data/copied_from_S3/mousebrainatlas-data/CSHL_volumes/atlasV7/atlasV7_10.0um_scoreVolume/score_volumes'\n",
    "files = os.listdir(VOL_DIR)\n",
    "volume_files = sorted([f for f in files if f.endswith('.npy') and surround == ('surround' in f) and 'test' not in f])\n",
    "origin_files = sorted([f for f in files if f.endswith('.txt') and surround == ('surround' in f) and 'test' not in f])\n",
    "    \n",
    "structure_volume_origin = {}\n",
    "for volume_filename, origin_filename in zip(volume_files, origin_files):\n",
    "    prefix = os.path.splitext(volume_filename)[0]\n",
    "    structure = prefix.replace('atlasV7_10.0um_scoreVolume_', '').replace('_surround_200um', '')\n",
    "    if structure not in origin_filename:\n",
    "        print(structure, origin_filename)\n",
    "        break\n",
    "    \n",
    "    try:\n",
    "        color = colors[structure.upper()]\n",
    "    except:\n",
    "        sided = '{}_R'.format(structure.upper())\n",
    "        color = colors[sided]\n",
    "\n",
    "    volume = np.load(os.path.join(VOL_DIR, volume_filename))\n",
    "    origin = np.loadtxt(os.path.join(VOL_DIR, origin_filename))\n",
    "    \n",
    "    volume = np.rot90(volume, axes=(0,1))\n",
    "    volume = np.flip(volume, axis=0)\n",
    "    volume[volume > 0.8] = color\n",
    "    volume = volume.astype(np.uint8)\n",
    "    \n",
    "    structure_volume_origin[structure] = (volume, origin)\n",
    "print(structure_volume_origin.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_length = 1000\n",
    "y_length = 1000\n",
    "z_length = 300\n",
    "full_brain_volume_annotated = np.zeros((x_length, y_length, z_length), dtype=np.uint32)\n",
    "\n",
    "for structure, (volume, origin) in structure_volume_origin.items():  \n",
    "    \n",
    "    x, y, z = origin\n",
    "    x_start = int(x) + x_length // 2\n",
    "    y_start = int(y) + y_length // 2\n",
    "    z_start = int(z) // 2 + z_length // 2\n",
    "    x_end = x_start + volume.shape[0]\n",
    "    y_end = y_start + volume.shape[1]\n",
    "    z_end = z_start + (volume.shape[2] + 1) // 2\n",
    "\n",
    "    z_indices = [z for z in range(volume.shape[2]) if z % 2 == 0]\n",
    "    volume = volume[:, :, z_indices]\n",
    "    full_brain_volume_annotated[x_start:x_end, y_start:y_end,z_start:z_end] += volume\n",
    "\n",
    "\n",
    "all_volume_layer = neuroglancer.SegmentationLayer(\n",
    "    source = neuroglancer.LocalVolume(\n",
    "        data=full_brain_volume_annotated, \n",
    "        dimensions=neuroglancer.CoordinateSpace(names=['x', 'y', 'z'], units='um', scales=[10, 10, 20]), \n",
    "        voxel_offset=(0, 0, 0)\n",
    "    ),\n",
    ")\n",
    "\n",
    "with viewer.txn() as s:\n",
    "    s.layers.clear()\n",
    "    s.layers['all'] = all_volume_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'file:///net/birdstore/Active_Atlas_Data/data_root/pipeline_data/test'\n",
    "factor = (2, 2, 1)\n",
    "volumes = tinybrain.downsample_segmentation(full_brain_volume_annotated, factor=factor, num_mips=2, sparse=False)\n",
    "volumes.insert(0, full_brain_volume_annotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = CloudVolume.create_new_info(\n",
    "    num_channels = 1,\n",
    "    layer_type = 'segmentation',\n",
    "    data_type = 'uint32', # Channel images might be 'uint8'\n",
    "    encoding = 'compressed_segmentation', # raw, jpeg, compressed_segmentation, fpzip, kempressed\n",
    "    resolution = [10000, 10000, 20000], # Voxel scaling, units are in nanometers\n",
    "    voxel_offset = [0, 0, 0], # x,y,z offset in voxels from the origin\n",
    "    chunk_size = [512, 512, 16], # units are voxels\n",
    "    volume_size = full_brain_volume_annotated.shape, # e.g. a cubic millimeter dataset\n",
    ")\n",
    "vol = CloudVolume(path, info=info, compress=False, progress=False)\n",
    "\n",
    "for mip, volume in enumerate(volumes):\n",
    "    vol.add_scale(np.array(factor) ** mip)\n",
    "    vol.commit_info()\n",
    "    vol = CloudVolume(path, mip=mip, compress=False, progress=False)\n",
    "    vol[:, :, :] = volume[:, :, :]\n",
    "    \n",
    "vol.info['segment_properties'] = 'names'\n",
    "vol.commit_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOL_DIR = '/net/birdstore/Active_Atlas_Data/data_root/CSHL_volumes'\n",
    "atlas = 'atlasV8'\n",
    "outfile =  os.path.join(VOL_DIR, atlas, 'full_brain_volume_annotated.npy')\n",
    "np.save(outfile, full_brain_volume_annotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudpath = f'file://{VOL_DIR}/{atlas}/mesh'\n",
    "info = CloudVolume.create_new_info(\n",
    "    num_channels = 1,\n",
    "    layer_type = 'segmentation',\n",
    "    data_type = 'uint32', # Channel images might be 'uint8'\n",
    "    encoding = 'raw', # raw, jpeg, compressed_segmentation, fpzip, kempressed\n",
    "    resolution = [10000, 10000, 20000], # Voxel scaling, units are in nanometers\n",
    "    voxel_offset = [0, 0, 0], # x,y,z offset in voxels from the origin\n",
    "    chunk_size = [512, 512, 16], # units are voxels\n",
    "    volume_size = full_brain_volume_annotated.shape, # e.g. a cubic millimeter dataset\n",
    ")\n",
    "vol = CloudVolume(cloudpath, mip=0, info=info, compress=False, progress=False)\n",
    "vol.commit_info()\n",
    "vol[:, :, :] = full_brain_volume_annotated[:, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tq = LocalTaskQueue(parallel=2)\n",
    "tasks = tc.create_meshing_tasks(cloudpath, mip=0, compress=False, progress=True)\n",
    "tq.insert(tasks)\n",
    "tasks = tc.create_mesh_manifest_tasks(cloudpath)\n",
    "tq.insert(tasks)\n",
    "tq.execute(progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol.viewer() # launches neuroglancer compatible web server on http://localhost:1337"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
