{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a86224cf",
   "metadata": {},
   "source": [
    "# Alignment Error Visualization\n",
    "\n",
    "This notebook collects COM data from the database and tries to quantify some alignment errors. The main results are shown in the plots at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116fa24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sqlalchemy import func\n",
    "from collections import OrderedDict\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "PIPELINE_ROOT = Path('./').absolute().parents[1]\n",
    "PIPELINE_ROOT = PIPELINE_ROOT.as_posix() + '/src'\n",
    "sys.path.append(PIPELINE_ROOT)\n",
    "print(PIPELINE_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9fa884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from library.controller.sql_controller import SqlController\n",
    "from library.image_manipulation.filelocation_manager import FileLocationManager\n",
    "from library.utilities.utilities_process import M_UM_SCALE, SCALING_FACTOR, random_string, read_image, write_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6342efe3-8054-4acd-9dc6-8a5d22d87ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_coms(animal):\n",
    "    \"\"\"\n",
    "    Lists the COMs from the annotation session table. The data\n",
    "    is stored in meters so you will want to convert it to micrometers\n",
    "    and then by the resolution of the scan run.\n",
    "    \"\"\"\n",
    "    sqlController = SqlController(animal)\n",
    "    xy_resolution = sqlController.scan_run.resolution\n",
    "    z_resolution = sqlController.scan_run.zresolution\n",
    "    coms = {}\n",
    "    annotator_id = 1 # Hardcoded to edward\n",
    "    com_dictionaries = sqlController.get_com_dictionary(prep_id=animal, annotator_id=annotator_id)\n",
    "    for k, v in com_dictionaries.items():\n",
    "        #x = round(v[0] * M_UM_SCALE / xy_resolution, 2)\n",
    "        #y = round(v[1] * M_UM_SCALE / xy_resolution, 2)\n",
    "        #z = round(v[2] * M_UM_SCALE / z_resolution, 2)\n",
    "        x = round(v[0] * M_UM_SCALE , 2)\n",
    "        y = round(v[1] * M_UM_SCALE , 2)\n",
    "        z = round(v[2] * M_UM_SCALE , 2)\n",
    "        coms[k] = (x,y,z)\n",
    "\n",
    "    return coms\n",
    "\n",
    "def apply_affine_transformations(points, matrix):\n",
    "    \"\"\"\n",
    "    Applies an affine transformation to a set of (x, y, z) coordinates.\n",
    "    \n",
    "    Parameters:\n",
    "        points (array-like): A list or array of shape (N, 3) containing N points in (x, y, z) format.\n",
    "        matrix (array-like): A 4x4 affine transformation matrix.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Transformed points as an (N, 3) array.\n",
    "    \"\"\"\n",
    "    points = np.asarray(points)\n",
    "    matrix = np.asarray(matrix)\n",
    "    \n",
    "    if points.shape[1] != 3:\n",
    "        raise ValueError(\"Each point must have exactly three coordinates (x, y, z).\")\n",
    "    if matrix.shape != (4, 4):\n",
    "        raise ValueError(\"The transformation matrix must be a 4x4 matrix.\")\n",
    "    \n",
    "    # Convert points to homogeneous coordinates by adding a 1 to each point\n",
    "    ones = np.ones((points.shape[0], 1))\n",
    "    homogeneous_points = np.hstack([points, ones])\n",
    "    \n",
    "    # Apply the affine transformation\n",
    "    transformed_points = homogeneous_points @ matrix.T\n",
    "    \n",
    "    # Convert back to Cartesian coordinates\n",
    "    return transformed_points[:, :3]\n",
    "\n",
    "def apply_affine_transform(point, matrix):\n",
    "    \"\"\"\n",
    "    Applies an affine transformation to a 3D point.\n",
    "\n",
    "    Parameters:\n",
    "    point (tuple or list): A tuple (x, y, z) representing the 3D point.\n",
    "    matrix (numpy array): A 4x4 affine transformation matrix.\n",
    "\n",
    "    Returns:\n",
    "    numpy array: Transformed (x', y', z') coordinates as a numpy array.\n",
    "    \"\"\"\n",
    "    if len(point) != 3:\n",
    "        raise ValueError(\"Point must be a 3-element tuple or list (x, y, z)\")\n",
    "    \n",
    "    if matrix.shape != (4, 4):\n",
    "        raise ValueError(\"Matrix must be a 4x4 numpy array\")\n",
    "    \n",
    "    # Convert the point to homogeneous coordinates\n",
    "    homogeneous_point = np.array([point[0], point[1], point[2], 1])\n",
    "    \n",
    "    # Apply the transformation\n",
    "    transformed_point = np.dot(matrix, homogeneous_point)\n",
    "    \n",
    "    # Return the transformed x, y, z coordinates (ignoring the homogeneous coordinate)\n",
    "    return transformed_point[:3]\n",
    "\n",
    "def absolute_sum(l):\n",
    "    la = np.array(l)\n",
    "    #nabs = np.abs(np.array(la))\n",
    "    return np.sum(la, axis=0)\n",
    "\n",
    "def plot_xyz_point(xyz):\n",
    "    x,y,z = xyz\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Plot the point\n",
    "    ax.scatter(x, y, z, color='r', s=100, label=f'Point ({x}, {y}, {z})')\n",
    "    \n",
    "    # Set labels\n",
    "    ax.set_xlabel('X Axis')\n",
    "    ax.set_ylabel('Y Axis')\n",
    "    ax.set_zlabel('Z Axis')\n",
    "    ax.set_title('3D Coordinate Plot')\n",
    "    \n",
    "    # Set limits\n",
    "    ax.set_xlim([0, 1320])\n",
    "    ax.set_ylim([0, 800])\n",
    "    ax.set_zlim([0, 1140])\n",
    "    \n",
    "    # Show grid\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44ad938",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397b771f-50da-4219-992e-0d7d0b96b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_structures = list_coms('Atlas')\n",
    "allen_structures = list_coms('Allen')\n",
    "\n",
    "\n",
    "common_structures = set()\n",
    "\n",
    "common_keys = sorted(list(allen_structures.keys() & atlas_structures.keys()))\n",
    "atlas_items = {k:v for k,v in atlas_structures.items() if k in common_keys}\n",
    "atlas_points = list(map(list, atlas_items.values()))\n",
    "print(len(atlas_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fee77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "affine_transform0 = np.array([\n",
    "    [ 9.36873602e-01,  6.25910930e-02,  3.41078823e-03,  4.07945327e+02],\n",
    "    [ 5.68396089e-04,  1.18742192e+00,  6.28369930e-03,  4.01267566e+01],\n",
    "    [-1.27831427e-02,  8.42516452e-03,  1.11913658e+00, -6.42895756e+01],\n",
    "    [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00]\n",
    " ]\n",
    ")\n",
    "affine_transform1 = np.array([\n",
    " [ 9.36873602e-01,  5.68396089e-04, -1.27831427e-02,  4.07945327e+02],\n",
    " [ 6.25910930e-02,  1.18742192e+00,  8.42516452e-03,  4.01267566e+01],\n",
    " [ 3.41078823e-03,  6.28369930e-03,  1.11913658e+00, -6.42895756e+01],\n",
    " [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00]\n",
    " ]\n",
    ")\n",
    "#error0 = [135845.  14108.  21411.]\n",
    "#error1 = [ 3276. 45718. 24330.] [148290.   6973.  25009.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3499fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_set = apply_affine_transformations(atlas_points, affine_transform0)\n",
    "#print(big_set)\n",
    "# rotating, sag to coronal\n",
    "# x becomes z\n",
    "# y stays the same\n",
    "# z becomes x\n",
    "x = 1000\n",
    "y = 600\n",
    "z = 800\n",
    "test_point = (x, y, z)\n",
    "SCA = (914, 238, 569)\n",
    "sag = ()\n",
    "plot_xyz_point(test_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0faee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "df_list = []\n",
    "for structure in common_keys:\n",
    "    atlas0 = atlas_structures[structure]\n",
    "    allen = np.array(allen_structures[structure])    \n",
    "    #transformed = apply_affine_transform(atlas0, affine_transform0)\n",
    "    #transformed = [round(x,0) for x in transformed]\n",
    "    difference = [round(a - b, 0) for a, b in zip(allen, atlas0)]\n",
    "    errors.append(difference)\n",
    "    #print(structure, atlas_structures[structure], allen_structures[structure], transformed, difference)\n",
    "    row = [structure, atlas_structures[structure], allen, difference]\n",
    "    df_list.append(row)\n",
    "result = absolute_sum(errors)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90601415",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['structure', 'atlas unaligned', 'allen', 'abs difference']\n",
    "df = pd.DataFrame(df_list, columns=columns)\n",
    "df.index.name = 'Index'\n",
    "df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f59c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_table(brains, person_id, input_type_id, save_path):\n",
    "    df_save = prepare_table_for_save(\n",
    "        brains,\n",
    "        person_id=person_id,\n",
    "        input_type_id=input_type_id\n",
    "    )\n",
    "    df_save.to_csv(save_path, index=False)\n",
    "    \n",
    "    df = prepare_table_for_plot(\n",
    "        brains,\n",
    "        person_id=person_id,\n",
    "        input_type_id=input_type_id\n",
    "    )\n",
    "\n",
    "    return df_save, df\n",
    "\n",
    "def get_brain_coms(brains, person_id, input_type_id):\n",
    "    brain_coms = {}\n",
    "    for brain in brains:\n",
    "        brain_coms[brain] = query_brain_coms(\n",
    "            brain,\n",
    "            person_id=person_id,\n",
    "            input_type_id=input_type_id\n",
    "        )\n",
    "        # A temporary hack: for ('DK55', corrected), use ('DK55', aligned)\n",
    "        if (brain, input_type_id) == ('DK55', 2):\n",
    "            brain_coms[brain] = query_brain_coms(\n",
    "                brain,\n",
    "                person_id=person_id,\n",
    "                input_type_id=4\n",
    "            )\n",
    "    return brain_coms\n",
    "\n",
    "def prepare_table_for_save(brains, person_id, input_type_id):\n",
    "    brain_coms = get_brain_coms(brains, person_id, input_type_id)\n",
    "\n",
    "    data = {}\n",
    "    data['name'] = []\n",
    "    for s in common_structures:\n",
    "        for c in ['dx', 'dy', 'dz', 'dist']:\n",
    "            data['name'] += [f'{s}_{c}']\n",
    "    for brain in brain_coms.keys():\n",
    "        data[brain] = []\n",
    "        offset = [brain_coms[brain][s] - atlas_coms[s]\n",
    "                  if s in brain_coms[brain] else [np.nan, np.nan, np.nan]\n",
    "                  for s in common_structures]\n",
    "        offset = np.array(offset)\n",
    "        scale = np.array([10, 10, 20])\n",
    "        dx, dy, dz = (offset * scale).T\n",
    "        dist = np.sqrt(dx * dx + dy * dy + dz * dz)\n",
    "        for dx_i, dy_i, dz_i, dist_i in zip(dx, dy, dz, dist):\n",
    "            data[brain] += [dx_i, dy_i, dz_i, dist_i]\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n",
    "\n",
    "def prepare_table_for_plot(brains, person_id, input_type_id):\n",
    "    brain_coms = get_brain_coms(brains, person_id, input_type_id)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for brain in brain_coms.keys():\n",
    "        offset = [brain_coms[brain][s] - atlas_coms[s]\n",
    "                  if s in brain_coms[brain] else [np.nan, np.nan, np.nan]\n",
    "                  for s in common_structures]\n",
    "        offset = np.array(offset)\n",
    "        scale = np.array([10, 10, 20])\n",
    "        dx, dy, dz = (offset * scale).T\n",
    "        dist = np.sqrt(dx * dx + dy * dy + dz * dz)\n",
    "\n",
    "        df_brain = pd.DataFrame()\n",
    "\n",
    "        data = {}\n",
    "        data['structure'] = common_structures\n",
    "        data['value'] = dx\n",
    "        data['type'] = 'dx'\n",
    "        df_brain = df_brain.append(pd.DataFrame(data), ignore_index=True)\n",
    "\n",
    "        data = {}\n",
    "        data['structure'] = common_structures\n",
    "        data['value'] = dy\n",
    "        data['type'] = 'dy'\n",
    "        df_brain = df_brain.append(pd.DataFrame(data), ignore_index=True)\n",
    "\n",
    "        data = {}\n",
    "        data['structure'] = common_structures\n",
    "        data['value'] = dz\n",
    "        data['type'] = 'dz'\n",
    "        df_brain = df_brain.append(pd.DataFrame(data), ignore_index=True)\n",
    "\n",
    "        data = {}\n",
    "        data['structure'] = common_structures\n",
    "        data['value'] = dist\n",
    "        data['type'] = 'dist'\n",
    "        df_brain = df_brain.append(pd.DataFrame(data), ignore_index=True)\n",
    "\n",
    "        df_brain['brain'] = brain\n",
    "        df = df.append(df_brain, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e9b799-b0f7-4bf3-9768-cf4c5db960f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df, ymin, ymax, ystep, title):\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(16, 12), dpi=200)\n",
    "    \n",
    "    sns.boxplot(ax=ax[0], x=\"structure\", y=\"value\", hue=\"type\", data=df)\n",
    "    ax[0].xaxis.grid(True)\n",
    "    ax[0].set_xlabel('Structure')\n",
    "    ax[0].set_ylabel('um')\n",
    "    ax[0].set_title('full dynamic range')\n",
    "    \n",
    "    sns.boxplot(ax=ax[1], x=\"structure\", y=\"value\", hue=\"type\", data=df)\n",
    "    ax[1].xaxis.grid(True)\n",
    "    ax[1].set_ylim(ymin, ymax)\n",
    "    ax[1].yaxis.set_ticks(np.arange(ymin, ymax + 1, ystep))\n",
    "    ax[0].set_xlabel('Structure')\n",
    "    ax[1].set_ylabel('um')\n",
    "    ax[1].set_title('zoom in')\n",
    "    \n",
    "    fig.suptitle(title, y=0.92)\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "figs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a021b972",
   "metadata": {},
   "source": [
    "## Rigid Alignment Error\n",
    "\n",
    "Rigid alignment error is computed as follows:\n",
    "1. Anotomist manually annotate the COMs for each brain.\n",
    "2. Computer finds the best transformation between atlas COMs and **anotomist's manual COMs**. The transformation is restricted to rigid + uniform scaling.\n",
    "3. Using the transformation, the **anotomist's manual COMs** are brought to the atlas space.\n",
    "4. The errors between the 2 sets of COMs are calculated, and displayed in the following plots.\n",
    "\n",
    "The errors for a single structure are quantified by 4 numbers: dx, dy, dz, dist. (dx, dy, dz) are the offset. dist is the corresponding distance of the offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b078e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_coms = get_brain_coms(brains_to_examine,person_id=28,\n",
    "    input_type_id=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee68c20f-5af1-430d-a347-6ed2954d568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# person is bili, input_type is aligned\n",
    "df_save, df = prepare_table(\n",
    "    brains_to_examine,\n",
    "    person_id=28,\n",
    "    input_type_id=4,\n",
    "    save_path='../data/rigid-alignment-error.csv'\n",
    ")\n",
    "df_save.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf2cb73-f780-4a26-8a97-b147faa40d99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plot(df, -1000, 1000, 100, 'Rigid Alignment Error')\n",
    "figs.append(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89baf1fe-8eca-47b7-9648-303a25087ea5",
   "metadata": {},
   "source": [
    "## Rigid Alignment Error After Correction\n",
    "\n",
    "After reviewing the rigid alignment error plots, Beth manually re-annotatted the significant outliers as a correction. With this updated data, we compute the alignment error again using the same method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc08f3-cee9-4e5e-abcb-eaa917224434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# person is bili, input_type is corrected\n",
    "df_save, df = prepare_table(\n",
    "    brains_to_examine,\n",
    "    person_id=28,\n",
    "    input_type_id=2,\n",
    "    save_path='../data/rigid-alignment-error-after-correction.csv'\n",
    ")\n",
    "df_save.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f283a84-572e-4814-9dc1-e75314222e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot(df, -1000, 1000, 100, 'Rigid Alignment Error After Correction')\n",
    "figs.append(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47847d1",
   "metadata": {},
   "source": [
    "## Rough Alignment Error\n",
    "\n",
    "**Rough alignment** is an **automatic method** to find the best 3D affine transformation between 2 brains, solely based on the thumbnail-resolution gray value images. Rough alignment is planned to be the first step of an automatic pipeline, which defines the starting points for Kui's automatic detection method.\n",
    "\n",
    "We start with an anotomist manually annotate the COMs extensively for one brain (DK52).\n",
    "\n",
    "Rough alignment error is computed as follows:\n",
    "1. Computer finds the best 3D affine transformation between DK52 and the brain, as determined by aligning the gray value images.\n",
    "2. Using the transformation, the DK52 COMs are brought to that brain's space. And we call it the **rough COMs** of the brain.\n",
    "3. Computer finds the best transformation between atlas COMs and **rough COMs**. The transformation is restricted to rigid + uniform scaling.\n",
    "4. Using the transformation, the **rough COMs** are brought to the atlas space.\n",
    "5. The errors between the 2 sets of COMs are calculated, and displayed in the following plots.\n",
    "\n",
    "The errors for a single structure are quantified by 4 numbers: dx, dy, dz, dist. (dx, dy, dz) are the offset. dist is the corresponding distance of the offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d501178-b8c8-4f97-a180-a4cbab24e66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# person is ed, input_type is aligned\n",
    "df_save, df = prepare_table(\n",
    "    brains_to_examine,\n",
    "    person_id=1,\n",
    "    input_type_id=4,\n",
    "    save_path='../data/rough-alignment-error.csv'\n",
    ")\n",
    "df_save.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42f5165-b897-4be6-9f97-a3d35b51d3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot(df, -1000, 1000, 100, 'Rough Alignment Error')\n",
    "figs.append(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c16da1-ec3f-4d28-a553-98285383940a",
   "metadata": {},
   "source": [
    "## Generate Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34d3bf4-a147-4816-afcc-959cc4850421",
   "metadata": {},
   "outputs": [],
   "source": [
    "with PdfPages('../data/alignment-error.pdf') as pdf:\n",
    "    for fig in figs:\n",
    "        pdf.savefig(fig)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2bd29f7b10431261d8beeb897d602198a8ccc2be7cc6f93af9f327223ffe0508"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
