{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input FOLDER: /net/birdstore/Active_Atlas_Data/data_root/pipeline_data/DKBC008/preps/C1/thumbnail_cropped; (nfiles=143)\n",
      "001, R=0.07912018895149231, xshift=0.0050193266943097115, yshift=-0.002001373330131173, metric=0.008531675674021244\n",
      "002, R=-0.03177070617675781, xshift=-0.02011614665389061, yshift=-0.011303243227303028, metric=0.007138846907764673\n",
      "003, R=0.01824052259325981, xshift=0.010038006119430065, yshift=-0.003325685393065214, metric=0.006850961595773697\n",
      "004, R=-0.32652905583381653, xshift=0.037092987447977066, yshift=-0.00239649903960526, metric=0.01210288517177105\n",
      "005, R=0.014618219807744026, xshift=-0.06827574968338013, yshift=-0.010487490333616734, metric=0.017972705885767937\n",
      "006, R=-0.018106669187545776, xshift=0.005038648843765259, yshift=0.0019071630667895079, metric=0.007014119531959295\n",
      "007, R=0.04710515961050987, xshift=0.02382161095738411, yshift=-0.0016151164891198277, metric=0.003770112758502364\n",
      "008, R=-0.001123814727179706, xshift=0.0077179307118058205, yshift=0.023037679493427277, metric=0.027582095935940742\n",
      "009, R=0.2937752306461334, xshift=-0.027048947289586067, yshift=-0.029248526319861412, metric=0.04689294844865799\n",
      "010, R=-0.49829721450805664, xshift=0.01626048982143402, yshift=-0.0012223455123603344, metric=0.04406649246811867\n",
      "011, R=-0.011540648527443409, xshift=-0.016720933839678764, yshift=-0.015209716744720936, metric=0.012987873516976833\n",
      "012, R=-0.030665051192045212, xshift=0.021903470158576965, yshift=0.05722714215517044, metric=0.027491584420204163\n",
      "013, R=0.13246382772922516, xshift=-0.0046273497864604, yshift=-0.09303377568721771, metric=0.03612757474184036\n",
      "014, R=-0.0728265717625618, xshift=0.010725042782723904, yshift=0.003588269464671612, metric=0.007807567715644836\n",
      "015, R=0.09454523772001266, xshift=-0.015478881075978279, yshift=0.008497809991240501, metric=0.009661877527832985\n",
      "016, R=0.04778072237968445, xshift=-0.03278031200170517, yshift=0.060865405946969986, metric=0.03255046159029007\n",
      "017, R=0.28682392835617065, xshift=-0.047696519643068314, yshift=0.041443999856710434, metric=0.033159203827381134\n",
      "018, R=-0.07085783034563065, xshift=-0.035285912454128265, yshift=-0.03207693248987198, metric=0.025475677102804184\n",
      "019, R=0.005702141206711531, xshift=-0.0009508078801445663, yshift=-0.04455605149269104, metric=0.01424487866461277\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "animal = 'DKBC008'\n",
    "input = f'/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/{animal}/preps/C1/thumbnail_cropped'\n",
    "\n",
    "def load_image(file_path, pixel_type=torch.float32, device='cpu'):\n",
    "    \"\"\"Loads an image and converts it to a PyTorch tensor.\"\"\"\n",
    "    image = Image.open(file_path).convert('L')  # Convert to grayscale\n",
    "    transform = transforms.ToTensor()\n",
    "    image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    return image_tensor.to(device=device, dtype=pixel_type)\n",
    "\n",
    "class RigidTransform(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RigidTransform, self).__init__()\n",
    "        self.angle = nn.Parameter(torch.tensor(0.0))\n",
    "        self.tx = nn.Parameter(torch.tensor(0.0))\n",
    "        self.ty = nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "    def forward(self, image):\n",
    "        theta = torch.zeros(1, 2, 3, device=image.device)\n",
    "        theta[:, 0, 0] = torch.cos(self.angle)\n",
    "        theta[:, 0, 1] = -torch.sin(self.angle)\n",
    "        theta[:, 1, 0] = torch.sin(self.angle)\n",
    "        theta[:, 1, 1] = torch.cos(self.angle)\n",
    "        theta[:, 0, 2] = self.tx\n",
    "        theta[:, 1, 2] = self.ty\n",
    "        \n",
    "        grid = F.affine_grid(theta, image.size(), align_corners=False)\n",
    "        return F.grid_sample(image, grid, mode='bilinear', padding_mode='zeros', align_corners=False)\n",
    "\n",
    "class Registration:\n",
    "    def __init__(self):\n",
    "        self.input = input\n",
    "        self.registration_output = 'output'\n",
    "        self.debug = True  # Set debug to True for logging output during execution\n",
    "    \n",
    "    def align_images_pytorch(self, fixed_index, moving_index, num_iterations=1000, learning_rate=0.01):\n",
    "        # Set device\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        # if self.debug:\n",
    "        #     print(f\"Device: {device}\")\n",
    "\n",
    "        # Load images\n",
    "        fixed_file = Path(self.input) / f\"{fixed_index}.tif\"\n",
    "        moving_file = Path(self.input) / f\"{moving_index}.tif\"\n",
    "        \n",
    "        if not fixed_file.exists() or not moving_file.exists():\n",
    "            raise FileNotFoundError(f\"One or both of the files do not exist: {fixed_file}, {moving_file}\")\n",
    "        \n",
    "        fixed_image = load_image(fixed_file, device=device)\n",
    "        moving_image = load_image(moving_file, device=device)\n",
    "\n",
    "        # Initialize the transformation model\n",
    "        transform_model = RigidTransform().to(device)\n",
    "        \n",
    "        # Set up the optimizer\n",
    "        optimizer = torch.optim.Adam(transform_model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Optimization loop\n",
    "        for iteration in range(num_iterations):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Apply rigid transformation\n",
    "            transformed_image = transform_model(moving_image)\n",
    "            \n",
    "            # Calculate the loss (mean squared error between fixed and transformed moving image)\n",
    "            loss = F.mse_loss(transformed_image, fixed_image)\n",
    "            \n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # if self.debug and iteration % 100 == 0:\n",
    "            #     print(f\"Iteration {iteration}: Loss = {loss.item()}\")\n",
    "\n",
    "        # Extract transformation parameters\n",
    "        R = transform_model.angle.item()\n",
    "        x = transform_model.tx.item()\n",
    "        y = transform_model.ty.item()\n",
    "\n",
    "        metric = loss.item()  # Final loss as a metric\n",
    "\n",
    "        return R, x, y, metric\n",
    "\n",
    "# Main execution\n",
    "reg = Registration()\n",
    "files = sorted(os.listdir(input))\n",
    "nfiles = len(files)\n",
    "print(f\"Input FOLDER: {input}; ({nfiles=})\")\n",
    "\n",
    "output_file = f\"{animal}_registration_results.csv\"\n",
    "Path(reg.registration_output, output_file).parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(Path(reg.registration_output, output_file), 'w') as f:\n",
    "    for i in range(1, 20):\n",
    "        fixed_index = os.path.splitext(files[i - 1])[0]\n",
    "        moving_index = os.path.splitext(files[i])[0]\n",
    "\n",
    "        R, xshift, yshift, metric = reg.align_images_pytorch(fixed_index, moving_index)\n",
    "        result_line = f'{moving_index},{R},{xshift},{yshift},{metric}\\n'\n",
    "        print(result_line.strip())  # Print to console without newline\n",
    "        f.write(result_line)  # Write to file\n",
    "        \n",
    "print(f\"Results saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
